{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db61629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve, eigh\n",
    "from scipy.optimize import approx_fprime, rosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db78df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(f, x_0, N, damping_factor = 0.5, eps=1e-6):\n",
    "    x_values = [x_0]\n",
    "    f_values = [f(x_0)]\n",
    "\n",
    "    for i in range(N):\n",
    "        gradient = approx_fprime(x_values[-1], f)\n",
    "        hessian = approx_hessian(x_values[-1], f)\n",
    "\n",
    "        if not is_positive_definite(hessian):\n",
    "            hessian = hessian + damping_factor * np.eye(len(x_0))\n",
    "\n",
    "        d = solve(hessian, -gradient)\n",
    "        \n",
    "        x_values.append(x_values[-1] + d)\n",
    "        f_values.append(f(x_values[-1]))\n",
    "\n",
    "        if np.linalg.norm(d) < eps:\n",
    "            break\n",
    "\n",
    "    print('Newton\\'s method performed ' + str(i+1) + ' iterations')\n",
    "    return x_values, f_values\n",
    "\n",
    "def is_positive_definite(matrix, tol = 1e-04):\n",
    "    \n",
    "    # Compute the eigenvalues\n",
    "    eigenvalues = eigh(matrix, eigvals_only = True)\n",
    "    return np.all(eigenvalues > tol)\n",
    "\n",
    "\n",
    "def approx_hessian(x, f):\n",
    "    n = len(x)\n",
    "    hessian = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        def grad_i(y):\n",
    "            return approx_fprime(y, f)[i]\n",
    "        hess_i = approx_fprime(x, grad_i,epsilon=1e-6)\n",
    "        \n",
    "        for j in range(n):\n",
    "            if i <= j:\n",
    "                hessian[i, j] = hess_i[j]\n",
    "\n",
    "                hessian[j, i] = hessian[i, j]\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e881ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, x_0, alpha_0, apx_LS, N, eps = 1e-4):\n",
    "    x_values = [x_0]\n",
    "    f_values = [f(x_0)]\n",
    "\n",
    "    for i in range(N):\n",
    "        d = -approx_fprime(x_values[-1], f)\n",
    "\n",
    "        if apx_LS:\n",
    "            alpha = apx_line_search(f, x_values[-1], d, alpha_0=alpha_0)\n",
    "        else:\n",
    "            alpha = alpha_0\n",
    "            \n",
    "        # Update x\n",
    "        x_new = x_values[-1] + alpha*d\n",
    "        x_values.append(x_new)\n",
    "        f_values.append(f(x_new))\n",
    "        \n",
    "        # Stopping criterion\n",
    "        if np.linalg.norm(d)<eps:\n",
    "            break\n",
    "\n",
    "\n",
    "    print('Gradient descent method performed ' + str(i+1) + ' iterations')\n",
    "    return x_values, f_values\n",
    "\n",
    "def apx_line_search(f, x, d, alpha_0, c = 0.1, t = 0.9):\n",
    "\n",
    "    alpha = alpha_0\n",
    "    f_x = f(x)\n",
    "    \n",
    "    def phi(a):\n",
    "        return f(x+ a*d)\n",
    "    \n",
    "    phi_prime = approx_fprime(0, phi)\n",
    "    \n",
    "    while  phi(alpha) > f_x +c*alpha*phi_prime:\n",
    "        alpha *= t\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cee1d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_0 = np.array([1.0, 1.0, 1.0, 1.0])     \\n\\n     \\ndef f(x):\\n    return np.sum(x**2)\\n\\nx, val = gradient_descent(f, x_0, apx_LS=False)\\n\\ndisplay_results(x, val)\\n\\nx, val = gradient_descent(f, x_0, apx_LS=True)\\n\\ndisplay_results(x, val)\\n\\ndef f(x):\\n    Q = np.diag([100, 10, 1])\\n    return float(x.T @ Q @ x)\\n\\nx_0 = np.array([3,3,3])   \\n            \\nx, val = newton_method(f, x_0)   \\n\\ndisplay_results(x, val)  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to nicely display the results of our algorithm\n",
    "def display_results(x, values, prec=3):\n",
    "    np.set_printoptions(precision=prec, suppress=True)\n",
    "    \n",
    "    header = f\"{'Iteration':<12}{'x Values':<40}{'Function Value':<20}\"\n",
    "    separator = \"=\" * len(header)\n",
    "\n",
    "    print(header)\n",
    "    print(separator)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        x_values = ', '.join(f\"{val:.{prec}f}\" for val in x[i])\n",
    "        value_str = f\"{values[i]:.{prec}f}\"\n",
    "\n",
    "        print(f\"{i + 1:<12}{x_values:<40}{value_str:<40}\")\n",
    "\n",
    "'''x_0 = np.array([1.0, 1.0, 1.0, 1.0])     \n",
    "\n",
    "     \n",
    "def f(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "x, val = gradient_descent(f, x_0, apx_LS=False)\n",
    "\n",
    "display_results(x, val)\n",
    "\n",
    "x, val = gradient_descent(f, x_0, apx_LS=True)\n",
    "\n",
    "display_results(x, val)\n",
    "\n",
    "def f(x):\n",
    "    Q = np.diag([100, 10, 1])\n",
    "    return float(x.T @ Q @ x)\n",
    "\n",
    "x_0 = np.array([3,3,3])   \n",
    "            \n",
    "x, val = newton_method(f, x_0)   \n",
    "\n",
    "display_results(x, val)  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef909b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
